{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e620fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer # aqui importaremos um dataset para a utilização da decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f010a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "dataset = pd.DataFrame(data=data['data'], columns = data['feature_names'])\n",
    "'''o Data Frame esta sendo criado da seguinte forma, o primeirmo parametro \"data=data['data']\"\n",
    "   assume que o data frame sera construido a partir da chave data esta que esta dentro da dictionary data que foi \n",
    "   importada do sklearn. O segundo parametro são os nomes das colunas que são definidos por feature_names\n",
    "'''\n",
    "dataset #queremos determinar quando um vetor caracteristico é um tumor maligno ou benigno, para tal uma classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa8ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Aqui iremos fazer a divisão dos dados de treinamento e dados de teste'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.copy()\n",
    "Y = data['target'] #os dados ja vem rotulados da biblioteca sklearn\n",
    "'''sklearn ira fazer o split, adivisao de conjunto de treinamento e de teste'''\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33)\n",
    "\n",
    "#test size, definimos que 33% dos dados serão reservados para teste\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3073244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''uma vez separados os conjuntos de treinamento e de teste iremos agora fazer as predições utilizando decision trees'''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a06c4fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params() #parametros padrão, valores inicializados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6385f6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>12.700</td>\n",
       "      <td>12.17</td>\n",
       "      <td>80.88</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.08785</td>\n",
       "      <td>0.05794</td>\n",
       "      <td>0.02360</td>\n",
       "      <td>0.02402</td>\n",
       "      <td>0.1583</td>\n",
       "      <td>0.06275</td>\n",
       "      <td>...</td>\n",
       "      <td>13.65</td>\n",
       "      <td>16.92</td>\n",
       "      <td>88.12</td>\n",
       "      <td>566.9</td>\n",
       "      <td>0.13140</td>\n",
       "      <td>0.16070</td>\n",
       "      <td>0.09385</td>\n",
       "      <td>0.08224</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.09464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>18.030</td>\n",
       "      <td>16.85</td>\n",
       "      <td>117.50</td>\n",
       "      <td>990.0</td>\n",
       "      <td>0.08947</td>\n",
       "      <td>0.12320</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.06254</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.05780</td>\n",
       "      <td>...</td>\n",
       "      <td>20.38</td>\n",
       "      <td>22.02</td>\n",
       "      <td>133.30</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>0.12630</td>\n",
       "      <td>0.26660</td>\n",
       "      <td>0.42900</td>\n",
       "      <td>0.15350</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.08225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>16.350</td>\n",
       "      <td>23.29</td>\n",
       "      <td>109.00</td>\n",
       "      <td>840.4</td>\n",
       "      <td>0.09742</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>0.18110</td>\n",
       "      <td>0.08773</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.06218</td>\n",
       "      <td>...</td>\n",
       "      <td>19.38</td>\n",
       "      <td>31.03</td>\n",
       "      <td>129.30</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0.14150</td>\n",
       "      <td>0.46650</td>\n",
       "      <td>0.70870</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.09614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>25.730</td>\n",
       "      <td>17.46</td>\n",
       "      <td>174.20</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.11490</td>\n",
       "      <td>0.23630</td>\n",
       "      <td>0.33680</td>\n",
       "      <td>0.19130</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>33.13</td>\n",
       "      <td>23.58</td>\n",
       "      <td>229.30</td>\n",
       "      <td>3234.0</td>\n",
       "      <td>0.15300</td>\n",
       "      <td>0.59370</td>\n",
       "      <td>0.64510</td>\n",
       "      <td>0.27560</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.08815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>12.850</td>\n",
       "      <td>21.37</td>\n",
       "      <td>82.63</td>\n",
       "      <td>514.5</td>\n",
       "      <td>0.07551</td>\n",
       "      <td>0.08316</td>\n",
       "      <td>0.06126</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.06114</td>\n",
       "      <td>...</td>\n",
       "      <td>14.40</td>\n",
       "      <td>27.01</td>\n",
       "      <td>91.63</td>\n",
       "      <td>645.8</td>\n",
       "      <td>0.09402</td>\n",
       "      <td>0.19360</td>\n",
       "      <td>0.18380</td>\n",
       "      <td>0.05601</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.08151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>14.810</td>\n",
       "      <td>14.70</td>\n",
       "      <td>94.66</td>\n",
       "      <td>680.7</td>\n",
       "      <td>0.08472</td>\n",
       "      <td>0.05016</td>\n",
       "      <td>0.03416</td>\n",
       "      <td>0.02541</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>0.05348</td>\n",
       "      <td>...</td>\n",
       "      <td>15.61</td>\n",
       "      <td>17.58</td>\n",
       "      <td>101.70</td>\n",
       "      <td>760.2</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.10110</td>\n",
       "      <td>0.11010</td>\n",
       "      <td>0.07955</td>\n",
       "      <td>0.2334</td>\n",
       "      <td>0.06142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.07356</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>12.320</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.13850</td>\n",
       "      <td>0.12660</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>9.423</td>\n",
       "      <td>27.88</td>\n",
       "      <td>59.26</td>\n",
       "      <td>271.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.06059</td>\n",
       "      <td>...</td>\n",
       "      <td>10.49</td>\n",
       "      <td>34.24</td>\n",
       "      <td>66.50</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.06969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>13.770</td>\n",
       "      <td>22.29</td>\n",
       "      <td>90.63</td>\n",
       "      <td>588.9</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.12670</td>\n",
       "      <td>0.13850</td>\n",
       "      <td>0.06526</td>\n",
       "      <td>0.1834</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>...</td>\n",
       "      <td>16.39</td>\n",
       "      <td>34.01</td>\n",
       "      <td>111.60</td>\n",
       "      <td>806.9</td>\n",
       "      <td>0.17370</td>\n",
       "      <td>0.31220</td>\n",
       "      <td>0.38090</td>\n",
       "      <td>0.16730</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.09333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "418       12.700         12.17           80.88      495.0          0.08785   \n",
       "444       18.030         16.85          117.50      990.0          0.08947   \n",
       "370       16.350         23.29          109.00      840.4          0.09742   \n",
       "352       25.730         17.46          174.20     2010.0          0.11490   \n",
       "407       12.850         21.37           82.63      514.5          0.07551   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "511       14.810         14.70           94.66      680.7          0.08472   \n",
       "17        16.130         20.68          108.10      798.8          0.11700   \n",
       "170       12.320         12.39           78.85      464.1          0.10280   \n",
       "557        9.423         27.88           59.26      271.3          0.08123   \n",
       "196       13.770         22.29           90.63      588.9          0.12000   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "418           0.05794         0.02360              0.02402         0.1583   \n",
       "444           0.12320         0.10900              0.06254         0.1720   \n",
       "370           0.14970         0.18110              0.08773         0.2175   \n",
       "352           0.23630         0.33680              0.19130         0.1956   \n",
       "407           0.08316         0.06126              0.01867         0.1580   \n",
       "..                ...             ...                  ...            ...   \n",
       "511           0.05016         0.03416              0.02541         0.1659   \n",
       "17            0.20220         0.17220              0.10280         0.2164   \n",
       "170           0.06981         0.03987              0.03700         0.1959   \n",
       "557           0.04971         0.00000              0.00000         0.1742   \n",
       "196           0.12670         0.13850              0.06526         0.1834   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "418                 0.06275  ...         13.65          16.92   \n",
       "444                 0.05780  ...         20.38          22.02   \n",
       "370                 0.06218  ...         19.38          31.03   \n",
       "352                 0.06121  ...         33.13          23.58   \n",
       "407                 0.06114  ...         14.40          27.01   \n",
       "..                      ...  ...           ...            ...   \n",
       "511                 0.05348  ...         15.61          17.58   \n",
       "17                  0.07356  ...         20.96          31.48   \n",
       "170                 0.05955  ...         13.50          15.64   \n",
       "557                 0.06059  ...         10.49          34.24   \n",
       "196                 0.06877  ...         16.39          34.01   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "418            88.12       566.9           0.13140            0.16070   \n",
       "444           133.30      1292.0           0.12630            0.26660   \n",
       "370           129.30      1165.0           0.14150            0.46650   \n",
       "352           229.30      3234.0           0.15300            0.59370   \n",
       "407            91.63       645.8           0.09402            0.19360   \n",
       "..               ...         ...               ...                ...   \n",
       "511           101.70       760.2           0.11390            0.10110   \n",
       "17            136.80      1315.0           0.17890            0.42330   \n",
       "170            86.97       549.1           0.13850            0.12660   \n",
       "557            66.50       330.6           0.10730            0.07158   \n",
       "196           111.60       806.9           0.17370            0.31220   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "418          0.09385               0.08224          0.2775   \n",
       "444          0.42900               0.15350          0.2842   \n",
       "370          0.70870               0.22480          0.4824   \n",
       "352          0.64510               0.27560          0.3690   \n",
       "407          0.18380               0.05601          0.2488   \n",
       "..               ...                   ...             ...   \n",
       "511          0.11010               0.07955          0.2334   \n",
       "17           0.47840               0.20730          0.3706   \n",
       "170          0.12420               0.09391          0.2827   \n",
       "557          0.00000               0.00000          0.2475   \n",
       "196          0.38090               0.16730          0.3080   \n",
       "\n",
       "     worst fractal dimension  \n",
       "418                  0.09464  \n",
       "444                  0.08225  \n",
       "370                  0.09614  \n",
       "352                  0.08815  \n",
       "407                  0.08151  \n",
       "..                       ...  \n",
       "511                  0.06142  \n",
       "17                   0.11420  \n",
       "170                  0.06771  \n",
       "557                  0.06969  \n",
       "196                  0.09333  \n",
       "\n",
       "[188 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''iremos adicionar os dados de teste para serem feitas algumas predições com o modelo inicial '''\n",
    "\n",
    "X_test #conjunto de teste possui 188 elementos para serem preditos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89132ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test) #fazendo as predições dos dados de teste\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b2519bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9672131147540983"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sera feito agora uma comparação entre os dados preditos do conjunto de teste e os rotulos destes dados\n",
    "para termos ideia da precisão do algoritmo \n",
    "'''\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(Y_test, predictions)#rotulos originais do conjunto de teste e as predições \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2994f850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"96% de assertividade do algoritmo , uma outra forma de ver as predições é a partir da probabailidade \n",
    "associada a cada classificação, no caso temos duas classe apenas \n",
    "\"\"\"\n",
    "\n",
    "predictions_probability = clf.predict_proba(X_test)\n",
    "\n",
    "'''rray([[0., 1.],\n",
    "       [1., 0.],\n",
    "           .\n",
    "           .\n",
    "           .\n",
    "o que esta sendo dito aqui é que para o primeiro registro a probabilidade de classificador predizer o valor zero é 0\n",
    "e o valor um é 1. , ou seja 100%, de fato se vermos as predições o primeiro registro teve valor predito 1, as coisas são\n",
    "assim pois a arvore de decisão foi crescendo sem ter nunhum criterio de parada , logo ela chegou nos ramos finais \n",
    "nós puros onde a classificação só poderia ser uma coisa ou outra\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cb4bfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.05555556, 0.94444444],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.05555556, 0.94444444],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.05555556, 0.94444444],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [0.01869159, 0.98130841],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colocando um limitador de profundidade, de ramos que a arvore de decisão pode ter\n",
    "'''\n",
    "clf = DecisionTreeClassifier(max_depth = 4)\n",
    "predictions = clf.fit(X_train, Y_train)\n",
    "\n",
    "predictions.predict_proba(X_test)\n",
    "'''\n",
    "\n",
    "\"\"\"note que quando diminuimos a prfundidade dos ramos as probabilidades de 0 e 1 serem classificados como tais mudam\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ea2a16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574468085106383"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outro medidor de performance do modelo é o accuracy_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(Y_test, predictions)\n",
    "\"\"\"o algoritmo de identificação de cancer de mama tem alto grau de assertividade\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f6eae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60,   4],\n",
       "       [  4, 120]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''para entender melhor a respeito dos erros e acertos'''\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, predictions, labels= [0,1])\n",
    "\n",
    "'''([[ 60,   4],\n",
    "       [  4, 120]],\n",
    "    lembre-se temos 188 dados/registros de teste, quando a classe dos dados de teste é zero o modelo fez a predição correta \n",
    "    60 vezes, quando a classe do registro de teste era zero e o modelo fez a predição 1, ou seja errou , isso ocorreu 4 vezes\n",
    "    similarmente para 1, foram 4 erros e 120 acertos \n",
    " \n",
    "       '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8ec68a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      0.94      0.94        64\n",
      "      benign       0.97      0.97      0.97       124\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.95      0.95      0.95       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"uma outra forma de determinar a performance é através do calssification report\"\"\"\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, predictions, target_names = ['malignant', 'benign']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd88cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
